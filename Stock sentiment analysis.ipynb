{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6054c69-bb26-4500-bbe8-605ab283d153",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingRequiredAttributeException",
     "evalue": "Required configuration setting 'client_id' missing. \nThis setting can be provided in a praw.ini file, as a keyword argument to the Reddit class constructor, or as an environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingRequiredAttributeException\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m client_secret \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLIENT_SECRET\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSER_AGENT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m reddit \u001b[38;5;241m=\u001b[39m \u001b[43mpraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReddit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mclient_secret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                     \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthenticated with Reddit API successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n",
      "File \u001b[1;32m~\\.conda\\envs\\reddit_scraper\\lib\\site-packages\\praw\\util\\deprecate_args.py:46\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[0;32m     40\u001b[0m     warn(\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     45\u001b[0m     )\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_old_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\reddit_scraper\\lib\\site-packages\\praw\\reddit.py:259\u001b[0m, in \u001b[0;36mReddit.__init__\u001b[1;34m(self, site_name, config_interpolation, requestor_class, requestor_kwargs, token_manager, **config_settings)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, attribute) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mCONFIG_NOT_SET, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 259\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingRequiredAttributeException(\n\u001b[0;32m    260\u001b[0m             required_message\u001b[38;5;241m.\u001b[39mformat(attribute)\n\u001b[0;32m    261\u001b[0m         )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mclient_secret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mCONFIG_NOT_SET:\n\u001b[0;32m    263\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFor installed applications this value must be set to None via a keyword argument to the Reddit class constructor.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mMissingRequiredAttributeException\u001b[0m: Required configuration setting 'client_id' missing. \nThis setting can be provided in a praw.ini file, as a keyword argument to the Reddit class constructor, or as an environment variable."
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from textblob import TextBlob\n",
    "load_dotenv()\n",
    "client_id = os.getenv(\"CLIENT_ID\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "user_agent = os.getenv(\"USER_AGENT\")\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent)\n",
    "\n",
    "print(\"Authenticated with Reddit API successfully!\")\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  \n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)  \n",
    "    text = text.lower()  \n",
    "    return text\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity  \n",
    "subreddit = reddit.subreddit(\"stocks\")\n",
    "posts = []\n",
    "for post in subreddit.top(limit=100):\n",
    "    post_data = {\n",
    "        'title': post.title,\n",
    "        'score': post.score,\n",
    "        'url': post.url,\n",
    "        'content': post.selftext,\n",
    "        'title_sentiment': get_sentiment(post.title),\n",
    "        'content_sentiment': get_sentiment(post.selftext),\n",
    "    }\n",
    "    post_data['title'] = clean_text(post_data['title'])\n",
    "    post_data['content'] = clean_text(post_data['content'])\n",
    "    posts.append(post_data)\n",
    "df = pd.DataFrame(posts)\n",
    "df.to_csv('stocks_posts.csv', index=False)\n",
    "print(\"Data has been saved to 'stocks_posts.csv' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7238cf-5389-478f-8147-142585c94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('stocks_posts.csv')\n",
    "print(df.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe75d1-296c-4d41-b404-5ce082e7c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('stocks_posts.csv')  \n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef0942-ca45-42f6-a36e-15efb4244433",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in subreddit.top(limit=100):\n",
    "    try:\n",
    "        post_data = {\n",
    "            'title': clean_text(post.title),\n",
    "            'score': post.score,\n",
    "            'url': post.url,\n",
    "            'content': clean_text(post.selftext if post.selftext else ''),\n",
    "            'title_sentiment': get_sentiment(post.title),\n",
    "            'content_sentiment': get_sentiment(post.selftext if post.selftext else ''),\n",
    "            'created_date': pd.to_datetime(post.created_utc, unit='s'),\n",
    "            'num_comments': post.num_comments,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9e669-9301-4a8f-acf1-be565b292925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Authenticated: {reddit.read_only}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a3933-207b-49c7-b758-88147da8a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"stocks\")\n",
    "for post in subreddit.top(limit=5):\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f25a4a-79d3-4a2e-a57d-4d4bdc4b2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "for post in subreddit.top(limit=100):\n",
    "    try:\n",
    "        post_data = {\n",
    "            'title': clean_text(post.title),\n",
    "            'score': post.score,\n",
    "            'url': post.url,\n",
    "            'content': clean_text(post.selftext if post.selftext else ''),\n",
    "            'title_sentiment': get_sentiment(post.title),\n",
    "            'content_sentiment': get_sentiment(post.selftext if post.selftext else ''),\n",
    "            'created_date': pd.to_datetime(post.created_utc, unit='s'),\n",
    "            'num_comments': post.num_comments,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "        print(f\"Processed post: {post.title[:30]}...\")  \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing post: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70675d5-21e7-499b-9f6a-e12b0d35c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not posts:\n",
    "    print(\"No posts were processed.\")\n",
    "else:\n",
    "    print(f\"Processed {len(posts)} posts.\")\n",
    "    df = pd.DataFrame(posts)\n",
    "    df.to_csv('stocks_posts.csv', index=False)\n",
    "    print(\"Data has been saved to 'stocks_posts.csv' successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10064195-5f0c-4253-bdf8-a7bde9a07fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('stocks_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8997cb-38c5-4719-b2bf-2291f1e36024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2d0ee-6aab-4dfa-a698-54680da616df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7bfa6-2a09-48a8-a2e1-7a2588e2a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37676d-3dbf-4c60-b618-6923ce91c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69789908-f5b0-48a2-ae78-c67af0b5fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of duplicates:{df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea9ae4-856d-4e0b-aadc-3f68f8e5984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca74b73-5072-4f36-a016-b1c42e1f5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18d620-0c2b-499b-999e-43c4c8e4b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content_sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc916cf-6ec3-451e-9147-c7e94b3416cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633fae8-b16e-4d84-8fd8-c09c2e77c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd69f1a-13ea-4d73-9cd5-215c6216fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_sentiment']=df['title_sentiment'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca5e5a-8fee-4344-a90d-a082bf208fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content_sentiment']=df['content_sentiment'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed267711-ee68-4cee-b5bd-356ef9e39d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stocks_posts_cleaned.csv', index=False)\n",
    "print(\"Cleaned data saved to 'stocks_posts_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f111d53-c3dc-4906-8bef-56526335229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df['title_sentiment'], bins=20, alpha=0.7, label='Title Sentiment')\n",
    "plt.hist(df['content_sentiment'], bins=20, alpha=0.7, label='Content Sentiment')\n",
    "plt.legend()\n",
    "plt.title('Sentiment Score Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafbd05a-d3e4-4f93-aa54-4f0259a81f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6999d4-620a-49e2-bc60-7b0a585cd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "stock_data = yf.download(\"AAPL\", start=\"2021-01-01\", end=\"2023-12-31\")\n",
    "stock_data = stock_data[['Close']]\n",
    "stock_data.reset_index(inplace=True)\n",
    "stock_data.columns = ['date', 'close_price']\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f0436-07ca-4e51-a5aa-2645f699cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd628d-5068-43ab-9cd2-9eefcee3f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363daa3-5230-4302-b8fc-829fc3f0bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'created_date': 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612572a8-ebc8-46de-90c4-96f4a364dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05543537-2c1d-4683-9966-d1eacb33765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397d7e1-3c4e-44f6-891a-1ff0fe540e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in df:\", df.columns)\n",
    "print(\"Columns in stock_data:\", stock_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefffc6c-1fee-44c5-8dc0-855fa295c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data['created_date'] = post.created_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed0934-f894-43d9-a4d3-b7e9d5b0b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05c53d-20a2-4142-b0b4-7ad1d48da977",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_data.columns)\n",
    "print(stock_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9866338-fca8-4e53-93eb-7f699f75dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608d63e-7eaa-4496-a4c8-89ab5280cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data['date'] = pd.to_datetime(stock_data['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e189e-eae0-4ccf-9482-7b027febe868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3768855-c3c5-4969-9fcf-6dc1debc67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a049b-ca73-4b12-8219-dedd42f77a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['date'].isnull().sum())\n",
    "print(stock_data['date'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f9c892-c4d9-4091-9621-299717f75de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_data['date'].head())\n",
    "print(df['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628ef9e-d580-43eb-ab88-27d6eb455ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457c4dc-0135-41c3-9f60-d5b28f044891",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dates = set(df['date']).intersection(set(stock_data['date']))\n",
    "print(\"Common Dates:\", common_dates)\n",
    "print(\"Number of Common Dates:\", len(common_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df384be4-9fd2-42dc-8bc1-2cdbfd14c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in df:\", df.columns)\n",
    "print(\"Columns in stock_data:\", stock_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5cb294-52d9-4a24-a26f-54326b4c01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['date'])\n",
    "print(\"df 'date' column:\", df['date'].head())\n",
    "print(\"stock_data 'date' column:\", stock_data['date'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65e0ce-a762-40db-9042-180c84c17152",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(df, stock_data, left_on='date', right_on='date', how='inner')\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ded443-2d78-4ba1-8749-57a6dd6f3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c73156c-f581-4ffc-9c58-afc75d8b25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbdb1d-a8b1-4ba5-8067-40c18ffb100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8be2c-3dba-42f1-8b9c-9fe7dfbed15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = merged_data[['title_sentiment', 'content_sentiment', 'close_price']].corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd481c-5f2e-452b-b461-59ca63620183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(merged_data['date'], merged_data['close_price'], label='Close price')\n",
    "plt.plot(merged_data['date'], merged_data['title_sentiment'], label='Title Sentiment', alpha=0.7)\n",
    "plt.plot(merged_data['date'], merged_data['content_sentiment'], label='Content Sentiment', alpha=0.7)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Stock Price vs Sentiment Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea9533-3d10-4936-b733-810e43ee13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax1.plot(merged_data['date'], merged_data['close_price'], label='Close Price', color='blue')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Close Price', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(merged_data['date'], merged_data['title_sentiment'], label='Title Sentiment', color='green', alpha=0.7)\n",
    "ax2.plot(merged_data['date'], merged_data['content_sentiment'], label='Content Sentiment', color='orange', alpha=0.7)\n",
    "ax2.set_ylabel('Sentiment Scores', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "plt.title('Stock Price vs Sentiment Scores')\n",
    "fig.tight_layout()\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c91172-3000-4506-9d60-4bf51e988dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalize sentiment scores to the range of stock prices (0 to 100 for example)\n",
    "merged_data['title_sentiment_normalized'] = (merged_data['title_sentiment'] + 1) * 50  # Normalize to 0-100\n",
    "merged_data['content_sentiment_normalized'] = (merged_data['content_sentiment'] + 1) * 50  # Normalize to 0-100\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot Close Price\n",
    "plt.plot(merged_data['date'], merged_data['close_price'], label='Close Price', color='blue')\n",
    "\n",
    "# Plot Sentiment Scores\n",
    "plt.plot(merged_data['date'], merged_data['title_sentiment_normalized'], label='Title Sentiment', alpha=0.7, color='orange')\n",
    "plt.plot(merged_data['date'], merged_data['content_sentiment_normalized'], label='Content Sentiment', alpha=0.7, color='green')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Stock Price vs Sentiment Scores')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bfded-01b9-42ac-8ed4-5a5206146bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(merged_data['title_sentiment'], bins=20, alpha=0.7, label='Title Sentiment')\n",
    "plt.hist(merged_data['content_sentiment'], bins=20, alpha=0.7, label='Content Sentiment')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sentiment Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50118800-fc19-4af2-9af0-c7b62099fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(merged_data['content_sentiment'], merged_data['close_price'], alpha=0.5)\n",
    "plt.xlabel('Content Sentiment')\n",
    "plt.ylabel('Stock Volume')\n",
    "plt.title('Content Sentiment vs Stock Volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a410d2a-8286-445c-a00c-d1c7164f23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['price_change'] = merged_data['close_price'].diff().shift(-1)\n",
    "merged_data['price_direction'] = merged_data['price_change'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b31540-174e-47c4-8169-c69379965f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "features = merged_data[['title_sentiment', 'content_sentiment', 'close_price']]\n",
    "target = merged_data['price_direction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb2573-670c-45f1-8bec-83f9cd423aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e677f7e-5c65-485a-a6f0-e51762cc3daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stock_data_cleaned = pd.read_csv('stocks_posts_cleaned.csv')\n",
    "stock_data_cleaned.to_excel('stocks_posts_cleaned.xlsx', index=False, engine='openpyxl')\n",
    "print(\"CSV file has been successfully converted to Excel.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (reddit_scraper)",
   "language": "python",
   "name": "reddit_scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
